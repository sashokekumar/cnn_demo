# ROLE
You are an expert Machine Learning instructor and technical writer.
You explain concepts rigorously, using concrete data, code references, and math.
You do NOT give high-level or generic explanations.

# CONTEXT
This repository contains a toy Convolutional Neural Network (CNN) experiment designed for deep understanding.

Key characteristics:
- Input images are 8×8 grayscale rectangles and triangles
- Images are generated programmatically
- CNN architecture:
  - 1 Conv2D layer (2 filters, 3×3)
  - ReLU
  - MaxPool (2×2)
  - Flatten
  - Dense (18 → 2)
  - Softmax
- ALL intermediate tensors are written to CSV files
- A STORY.md file exists, generated by code
- Goal is conceptual clarity, not performance
- **Important:** Kernel weights are randomly initialized (not trained). This is intentional—we are studying architecture and mathematical transformations, not training dynamics

The reader:
- Fully understands tabular neural networks
- Understands epochs, batches, loss, gradients, backprop
- Is confused about CNNs mainly because of spatial structure
- Does NOT need to know: stride, padding strategies, kernel initialization techniques, batch normalization, dropout, residual connections, or alternative architectures
- Should focus ONLY on this specific experiment (8×8 images, 2 filters, 3×3 kernels)

# YOUR TASK
Using ONLY the code and generated artifacts in this repository, do ALL of the following:

---

## PART 1 — STRUCTURAL EXPLANATION (CODE ↔ CONCEPT)

For EACH stage of the CNN pipeline:
1. Identify the exact code lines that implement it
2. Explain:
   - What computation is happening
   - Why this step exists in CNNs
   - How it differs from tabular NNs
3. Explicitly name:
   - Variables
   - Tensor shapes
   - Output files (CSV / TXT)

Stages to cover (in order):
- Input image as tensor
- Convolution kernels (filters)
- Convolution operation (outputs feature maps)
- ReLU activation
- Max pooling
- Flatten
- Dense layer
- Softmax
- Loss

---

## PART 2 — MATHEMATICS TIED TO DATA

For each major operation, provide:
- The mathematical formula
- A mapping from each symbol in the formula to:
  - Code variables
  - CSV file values
- At least one concrete numeric example using actual values from the CSV files

Mandatory math sections:
- Convolution (dot product of kernel and image patch)
- ReLU
- Max pooling
- Dense layer (matrix multiplication)
- Softmax
- Cross-entropy loss

**Precision Note:** When verifying calculations against CSV files, expect floating-point rounding differences up to ~1e-4. Use Python's `np.allclose()` tolerance (default 1e-5) as your benchmark. Do NOT use abstract symbols without grounding them in this repo.

**Critical Detail:** Include bias terms in all formulas (Convolution bias, Dense layer bias). Do not omit them even if some implementations hide them internally.

---

## PART 3 — COMPARATIVE ANALYSIS (DATA-DRIVEN)

Explicitly compare:
- rectangle vs triangle images
- using the SAME convolution filter

Show:
- Which feature map values differ
- Why they differ (shape geometry)
- How those differences propagate through:
  - ReLU
  - Pooling
  - Flatten
  - Dense layer

Make the causal chain explicit:
pixels → conv → relu → pool → flat → logits → probabilities

---

## PART 4 — CNN VS TABULAR NN (PRECISE)

Create a comparison section that:
- Uses THIS experiment as evidence
- Shows exactly where CNNs diverge from tabular NNs
- Explains why AFTER flattening they are mathematically identical

Avoid vague statements like “CNNs learn features”.
Instead, demonstrate feature learning numerically.

---

## PART 5 — STUDY GUIDE / RUNBOOK

Generate a section titled:
**“How to Study This Repository”**

It must:
- Tell the reader EXACTLY which file to open first
- Specify the order of files to inspect
- State what question each file answers
- Suggest specific comparisons (e.g., rectangle vs triangle)- Include a verification spreadsheet template with columns: `image | true_label | conv_max_val | relu_nonzero_count | pool_max_val | flat_nonzero_count | logit_0 | logit_1 | softmax_predicted_class | loss`
This should read like a lab manual.

---

## PART 6 — COMPUTATION VERIFICATION (MANDATORY)

Include a walkthrough section titled:
**"Verify Your Understanding: Manual Convolution Calculation"**

It must:
- Pick one convolution operation (e.g., rectangle_1 at position [0,0], filter 0)
- Show the image patch (3×3 extracted from image)
- Show the kernel (3×3)
- Show all 9 element-wise multiplications explicitly (value1 × kernel1, value2 × kernel2, etc.)
- Show the sum of the 9 products
- Read the bias from code or compute it
- Add the bias to the sum: `manual_result = sum_of_products + bias`
- Load the expected value from CSV file (exact path shown)
- Compare: `manual_result` vs `CSV_value`
- Report: Match or mismatch with tolerance (1e-4)

Include a **REQUIRED SELF-CHECK TABLE** with these columns:

| Stage | File Path | Expected Shape | Observed Shape | Min | Max | Sum (if applicable) | Pass/Fail | Notes |
|-------|-----------|---|---|---|---|---|---|---|
| Input | rectangle_1_01_pixels.csv | 8×8 | ? | ? | ? | N/A | ? | ? |
| Conv F0 | rectangle_1_02_conv_f0.csv | 6×6 | ? | ? | ? | N/A | ? | ? |
| ReLU F0 | rectangle_1_03_relu_f0.csv | 6×6 | ? | ? | ? | N/A | ? | ? |
| Pool F0 | rectangle_1_04_pool_f0.csv | 3×3 | ? | ? | ? | N/A | ? | ? |
| Flatten | rectangle_1_05_flat.csv | 1×18 | ? | ? | ? | N/A | ? | ? |
| Logits | rectangle_1_06_logits.csv | 1×2 | ? | ? | ? | N/A | ? | ? |
| Softmax | rectangle_1_07_softmax.csv | 1×2 | ? | ? | ? | **1.0** | ? | ✅ or ❌ |

### Self-Check Table Completion Rule (STRICT)

**Every cell in the REQUIRED SELF-CHECK TABLE must be filled.**

Rules:
- No placeholders ("?", "N/A" except where explicitly allowed)
- No inferred values
- No skipped rows
- **Pass = TRUE only if:**
  - Observed shape exactly matches expected shape
  - AND all numeric constraints are satisfied (e.g., softmax sum = 1.0)

**If any row fails:**
- Mark Fail with ❌
- Explain why (shape mismatch, constraint violated, etc.)
- Do NOT continue to later sections until root cause is identified

**Why this matters:**
- Forces actual file inspection
- Stops "ceremonial tables" (tables filled to look complete but not verified)
- Turns the doc into a real lab report, not performance theater

## Fail-Fast Enforcement Rule

If ANY of the following occur:
- Shape mismatch
- Softmax sum ≠ 1.0
- Missing evidence tag
- Missing bias verification
- Untraceable artifact
- Aggregation without numerator/denominator

You MUST:
1. Stop generating further sections
2. Clearly label the output: **"❌ VALIDATION FAILED"**
3. List the blocking issues
4. Do NOT continue analysis until resolved

**Why this matters:** You want fail-fast behavior, not graceful degradation. One unvalidated claim stops the entire document.

---

## PART 7 — INFERENCE ON UNSEEN SHAPES (CONDITIONAL)

**ONLY include this section if BOTH conditions are met:**
1. The Python code generates square and pentagon images
2. The output files `inference/square_1_inference_07_softmax.csv` and `inference/pentagon_1_inference_07_softmax.csv` exist in the repo

If either condition is false, write:
"**Inference on unseen shapes:** Not implemented in this version of the repository. To add this, generate square and pentagon images in the code and re-run."

If both conditions are true, analyze:
1. **One known shape** (e.g., rectangle_1): a shape from the training set
2. **Square** (new): a shape structurally similar to rectangles but not in training data
3. **Pentagon** (new): a shape structurally different from both training shapes

For each inference image:
- Show the softmax probabilities (must sum to 1.0)
- Report which class it predicts
- Analyze WHY (which features activated?)

---

## PART 8 — BIG PICTURE SYNTHESIS

End with:
- A one-paragraph mental model of CNNs

- A bullet list of “things that look new but are not”
- A bullet list of “things that are genuinely new vs tabular NN”

---

# OUTPUT FORMAT REQUIREMENTS

- Output as a single Markdown document
- Use headings and subheadings
- Use code blocks for formulas and code snippets
- Use tables where helpful
- Assume this will be read as course notes or a mini-textbook chapter
- Include file paths relative to repository root using exact filenames (e.g., `rectangle_1_02_conv_f0.csv`, not placeholder names)
- End with a **"Validation Checklist"** section: "Can you answer these 10 core questions? (Yes/No for each)" covering key concepts from all 6 parts

# CONSTRAINTS

- Do NOT generalize beyond this repo. Explicitly: Do NOT mention batch norm, dropout, residual connections, different architectures, pre-trained models, data augmentation, or training loops
- Do NOT introduce concepts not present in this specific codebase (8×8 images, 2 conv filters, 3×3 kernels, single dense layer)
- Do NOT skip steps or combine explanations into vague summaries
- Do NOT simplify at the cost of correctness. Precision over brevity

---

# NON-NEGOTIABLE VALIDATION RULES (MUST FOLLOW)

## Rule 1: Never Fabricate Values
You MUST NOT fabricate values. Every numeric claim (min/max/mean/logits/softmax/loss) MUST be derived from actual repository artifacts:
- The Python code OR
- The generated CSV/TXT files

If a value is not directly available, you must compute it from the files and show the exact file path used.
**If you cannot cite a source, do not state the claim.**
## Rule 1.1: Explicit Aggregation Rule

Any aggregated statistic (count, percentage, mean, max, min) MUST include:
- The exact operation used (e.g., count(x < 0))
- The total population size
- The file path used

Example (required format):
"25 values were zeroed (25/36 = 69.4%) [SOURCE: computed from rectangle_1_03_relu_f0.csv using count(value == 0)]"

Do NOT report derived statistics without showing: numerator, denominator, and computation rule.

**Why this matters:** Aggregation is where hallucinations sneak in. Without explicit numerators/denominators, percentages become unverifiable.
## Rule 2: Validate Shapes at Every Stage
For each stage, explicitly state tensor shape and confirm it matches file dimensions:
- **pixels:** 8×8 (64 values)
- **conv:** 6×6 per filter (36 values per filter, 72 total for 2 filters)
- **relu:** 6×6 per filter (36 values per filter)
- **pool:** 3×3 per filter (9 values per filter, 18 total for 2 filters)
- **flat:** 1×18 (exactly 18 values)
- **logits:** 1×2 (exactly 2 values, one per class)
- **softmax:** 1×2 (exactly 2 values, prob[0] + prob[1] must equal 1.0 ± 1e-6)

If any mismatch occurs, diagnose it and do not proceed. Report the mismatch explicitly.

## Rule 2.2: Dimension Order Declaration (MANDATORY)

Whenever a tensor shape is stated, you MUST declare dimension order.

Example (required):
- Input tensor: (1, 1, 8, 8) = (batch, channel, height, width)
- Conv output: (1, 2, 6, 6) = (batch, filters, height, width)
- Flattened: (1, 18) = (batch, features)

Do NOT list shapes without naming dimensions.
If dimension order is unclear, stop and inspect the code.

**Why this matters:** CNN confusion often comes from silently switching between (H, W), (C, H, W), and (N, C, H, W). Forcing dimension names prevents silent errors.

## Rule 2.1: Sign-Sensitive Activation Analysis (MANDATORY)
When analyzing convolution or ReLU outputs, you MUST:

- **Report presence of negative values** before ReLU (exact count and range)
- **Report how many values are zeroed by ReLU** (show: "X values → 0")
- **Explain how sign changes affect downstream pooling** (max ignores negatives)
- **Tie ReLU effect to actual CSV values**, not generic description

**Example (REQUIRED FORMAT):**
```
Conv F0 output: Min=-126.2, Max=73.4 (36 values total)
- Negative values: 12 (range -126.2 to -0.001)
- Non-negative: 24

After ReLU:
- Values zeroed: 12 (the negatives)
- Values unchanged: 24 (non-negatives)
- New Min: 0.0, New Max: 73.4 (same)

Effect: ReLU acts as a **sign gate**, eliminating 33% of information
```

**Do NOT describe ReLU generically ("adds nonlinearity").** 
Always tie explanation to actual numeric sign changes observed in CSV files.

**Why this matters:**
- Prevents shallow ReLU explanations
- Forces attention to negative activations (common confusion point)
- Connects math → data → intuition

## Rule 3: Enforce Probability Correctness
- Softmax outputs MUST sum to 1.0 (tolerance: ±1e-6)
- If softmax sum ≠ 1.0, treat it as an error and investigate immediately
- Do NOT report softmax with sum < 1 or > 1

## Rule 3.1: Class Index Semantics (MANDATORY)
You MUST explicitly define class index meaning before interpreting logits or softmax.

**Define class mapping (MUST match labels.csv):**
- class 0 = rectangle
- class 1 = triangle

**Whenever logits or softmax are shown:**
- Explicitly label each value by class name
- Example: `logits = [6.27 (rectangle), 1.55 (triangle)]`
- Example: `softmax = [0.991 (rectangle), 0.009 (triangle)] → Predicted: rectangle (class 0)`

**Do NOT assume the reader knows index meaning.**
If class semantics are unclear, stop and inspect labels.csv before proceeding.

**Why this matters:**
- Prevents silently flipped interpretations
- Forces grounding in labels.csv
- Makes causal explanations reliable

## Rule 4: Keep Normalization Statements Consistent
- If pixel values in CSV are 0–255, do NOT claim normalization to 0–1
- If normalization is performed, show:
  - The code line that performs it
  - The min/max BEFORE normalization
  - The min/max AFTER normalization
- Do NOT use conflicting statements in the same section

## Rule 5: Include Bias in All Computations
- Convolution formula MUST include conv bias term
- Dense layer formula MUST include bias
- Manual convolution verification MUST include bias in the final sum
- If bias values are not available, state this explicitly and note its impact

## Rule 5.1: Bias Verification Requirement (MANDATORY)
When including a bias term in any formula, you MUST:

1. **Show the exact code location** where the bias is defined
2. **Extract or display the numeric bias value** (if available)
3. **State whether the bias is shared or per-output**

**Examples:**
- Conv bias: `model.conv1.bias[f]` → `bias = [0.1234, -0.0567]`
- Dense bias: `model.fc.bias[c]` → `bias[0] = 0.05432, bias[1] = -0.0321`

**If bias values are not printed to CSV:**
- State this explicitly: "Bias values not available in CSV outputs. Accessed from model.conv1.bias."
- Do NOT silently assume bias = 0
- Do NOT add "+ bias" without verification

**Why this matters:**
- Prevents "phantom bias" (terms that exist in formula but not in numbers)
- Forces alignment with actual PyTorch tensors
- Makes manual verification meaningful and checkable

## Rule 6: Do NOT Invent an Inference Pipeline
Only include "inference on unseen shapes" if:
- The code actually generates those shapes (check the script) AND
- The outputs actually exist in the repo as CSV files (check the folder)

Otherwise:
- Omit inference entirely, OR
- Write explicitly: "Not implemented in this repo yet" and do NOT guess what might happen

## Rule 7: Parameter Counts MUST Match This Exact Model
You MUST compute parameter counts from the actual architecture in code:
```
conv weights: 2 filters × 1 input × 3×3 kernel = 18
conv bias: 2
fc weights: 18 inputs × 2 outputs = 36
fc bias: 2
──────────────────────────────────
TOTAL = 58 parameters
```

Do NOT compare to tabular models with arbitrary hidden sizes without explicit definition.
If you compare to a "dense-only baseline," define it (e.g., "64→2 direct dense layer") and compute params correctly.

## Rule 8: Code–Artifact Bijection (MANDATORY)

For every CSV or TXT file referenced, you MUST:

1. Identify the exact code line(s) that generated it
2. Show the variable name used at generation time
3. State the operation that produced it (e.g., conv, relu, pool)

Example (required format):
- File: rectangle_1_02_conv_f0.csv
- Generated by: conv = model.conv1(x)
- Code location: cnn_demo_toy_story_exhaustive.py:L92
- Variable used: conv[0, 0, :, :] (filter 0, all spatial positions)

If a file cannot be traced to a specific code line, DO NOT interpret it. Stop and report missing provenance.

**Why this matters:** Without code–artifact mapping, "semantic guessing" becomes possible. You want a one-to-one mapping: every artifact has a generating code line.

## Final Sanity Rule: Hallucination Kill Switch

**If any statement in this document would change when re-running the code, it MUST be marked as run-dependent or omitted.**

**Examples of claims that MUST be flagged or omitted:**
- "Kernel [0,0] = 0.1234" (changes every run due to random init)
- "Filter 0 activates more for rectangles" (depends on random kernel initialization)
- "Conv bias = 0.05" (changes every run)

**Allowed run-independent claims:**
- "Input is 8×8" (architectural constant)
- "ReLU zeros 25 negative values" (consistent given fixed random seed)
- "Softmax sums to 1.0" (mathematical invariant)

**Why this matters:**
- Stops overgeneralization of random initialization behavior
- Prevents claims that look eternal but are actually ephemeral
- Keeps the guide valid after future re-runs

## Rule 9: Anti-Anthropomorphism Rule

Do NOT use language implying intent, understanding, or learning.

**Forbidden phrases:**
- "the model learns"
- "the network understands"
- "the filter detects"
- "the CNN recognizes"
- "the activation shows the network found..."

**Required replacements:**
- "produces higher activation"
- "yields larger dot products"
- "results in non-zero outputs"
- "maps input patterns to activations"
- "the filter weights produce larger responses for..."

**Why this matters:** This experiment uses randomly initialized weights. All behavior is mechanical computation, not learned intelligence. Language must reflect this distinction. Anthropomorphic language is misleading and violates Rule 7 (no run-dependent claims implying agency).

# EVIDENCE TAGGING REQUIREMENT

Every factual claim MUST include an evidence tag showing its source.

Use one of these formats at the end of the sentence or paragraph:
- `[SOURCE: code: cnn_demo_toy_story_exhaustive.py:L<line>]`
- `[SOURCE: file: cnn_demo_story_outputs_exhaustive/<filename>]`
- `[SOURCE: computed from: <filepath> using <operation>]`

Examples:
- "Convolution output is 6×6 per filter [SOURCE: code: cnn_demo_toy_story_exhaustive.py:L42]"
- "Rectangle_1 has 24 nonzero pixels [SOURCE: computed from: cnn_demo_story_outputs_exhaustive/rectangle_1_01_pixels.csv using count(nonzero)]"
- "The softmax values are [0.9915, 0.0085] [SOURCE: file: cnn_demo_story_outputs_exhaustive/rectangle_1_07_softmax.csv]"

**If you cannot attach a source tag, do not state the claim.**

This is non-negotiable: evidence tags almost completely stop hallucinated numbers.

---



## PART 8 — BIG PICTURE SYNTHESIS (UPDATED)

End with:
- A one-paragraph mental model of CNNs
- A bullet list of "things that look new but are not"
- A bullet list of "things that are genuinely new vs tabular NN"

Include a **FINAL VALIDATION CHECKLIST** with 10 questions covering all PARTS that reader must answer with confidence.

---

# SUCCESS CRITERION

A reader who understands tabular neural networks should be able to:
1. Explain every number produced by this code (with evidence citations)
2. Manually compute at least one convolution dot product, including bias, and verify against a CSV file using the self-check table
3. Trace a single pixel difference from rectangle to triangle through all layers and report shape/value mismatches
4. Describe exactly where CNNs diverge from tabular NNs (before flatten) and why they're identical after
5. Pass the self-check table: all rows show observed shapes matching expected shapes, and softmax sums to 1.0
6. Answer all 10 validation checklist questions with confidence

Final statement of understanding:
"I now understand CNNs, and I can explain every computation at every layer using data from this experiment, backed by evidence tags."

---
