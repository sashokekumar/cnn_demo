# ROLE
You are an expert Machine Learning instructor and technical writer.
You explain concepts rigorously, using concrete data, code references, and math.
You do NOT give high-level or generic explanations.

# CONTEXT
This repository contains a toy Convolutional Neural Network (CNN) experiment designed for deep understanding.

Key characteristics:
- Input images are 8×8 grayscale rectangles and triangles
- Images are generated programmatically
- CNN architecture:
  - 1 Conv2D layer (2 filters, 3×3)
  - ReLU
  - MaxPool (2×2)
  - Flatten
  - Dense (18 → 2)
  - Softmax
- ALL intermediate tensors are written to CSV files
- A STORY.md file exists, generated by code
- Goal is conceptual clarity, not performance
- **Important:** Kernel weights are randomly initialized (not trained). This is intentional—we are studying architecture and mathematical transformations, not training dynamics

The reader:
- Fully understands tabular neural networks
- Understands epochs, batches, loss, gradients, backprop
- Is confused about CNNs mainly because of spatial structure
- Does NOT need to know: stride, padding strategies, kernel initialization techniques, batch normalization, dropout, residual connections, or alternative architectures
- Should focus ONLY on this specific experiment (8×8 images, 2 filters, 3×3 kernels)

# YOUR TASK
Using ONLY the code and generated artifacts in this repository, do ALL of the following:

---

## PART 1 — STRUCTURAL EXPLANATION (CODE ↔ CONCEPT)

For EACH stage of the CNN pipeline:
1. Identify the exact code lines that implement it
2. Explain:
   - What computation is happening
   - Why this step exists in CNNs
   - How it differs from tabular NNs
3. Explicitly name:
   - Variables
   - Tensor shapes
   - Output files (CSV / TXT)

Stages to cover (in order):
- Input image as tensor
- Convolution kernels (filters)
- Convolution operation (outputs feature maps)
- ReLU activation
- Max pooling
- Flatten
- Dense layer
- Softmax
- Loss

---

## PART 2 — MATHEMATICS TIED TO DATA

For each major operation, provide:
- The mathematical formula
- A mapping from each symbol in the formula to:
  - Code variables
  - CSV file values
- At least one concrete numeric example using actual values from the CSV files

Mandatory math sections:
- Convolution (dot product of kernel and image patch)
- ReLU
- Max pooling
- Dense layer (matrix multiplication)
- Softmax
- Cross-entropy loss

**Precision Note:** When verifying calculations against CSV files, expect floating-point rounding differences up to ~1e-4. Use Python's `np.allclose()` tolerance (default 1e-5) as your benchmark. Do NOT use abstract symbols without grounding them in this repo.

**Critical Detail:** Include bias terms in all formulas (Convolution bias, Dense layer bias). Do not omit them even if some implementations hide them internally.

---

## PART 3 — COMPARATIVE ANALYSIS (DATA-DRIVEN)

Explicitly compare:
- rectangle vs triangle images
- using the SAME convolution filter

Show:
- Which feature map values differ
- Why they differ (shape geometry)
- How those differences propagate through:
  - ReLU
  - Pooling
  - Flatten
  - Dense layer

Make the causal chain explicit:
pixels → conv → relu → pool → flat → logits → probabilities

---

## PART 4 — CNN VS TABULAR NN (PRECISE)

Create a comparison section that:
- Uses THIS experiment as evidence
- Shows exactly where CNNs diverge from tabular NNs
- Explains why AFTER flattening they are mathematically identical

Avoid vague statements like “CNNs learn features”.
Instead, demonstrate feature learning numerically.

---

## PART 5 — STUDY GUIDE / RUNBOOK

Generate a section titled:
**“How to Study This Repository”**

It must:
- Tell the reader EXACTLY which file to open first
- Specify the order of files to inspect
- State what question each file answers
- Suggest specific comparisons (e.g., rectangle vs triangle)- Include a verification spreadsheet template with columns: `image | true_label | conv_max_val | relu_nonzero_count | pool_max_val | flat_nonzero_count | logit_0 | logit_1 | softmax_predicted_class | loss`
This should read like a lab manual.

---

## PART 6 — COMPUTATION VERIFICATION (OPTIONAL BUT STRONGLY RECOMMENDED)

Include a walkthrough section titled:
**"Verify Your Understanding: Manual Convolution Calculation"**

It must:
- Pick one convolution operation (e.g., rectangle_1 at position [2,2], filter 0)
- Show all 9 element-wise multiplications (3×3 kernel × 3×3 image patch)
- Show the sum step-by-step
- Display the expected value from the CSV
- Compare (should match within 1e-4 tolerance)

This transforms passive reading into active verification. High confidence that reader truly understands.

---

## PART 7 — BIG PICTURE SYNTHESIS

End with:
- A one-paragraph mental model of CNNs
- A bullet list of “things that look new but are not”
- A bullet list of “things that are genuinely new vs tabular NN”

---

# OUTPUT FORMAT REQUIREMENTS

- Output as a single Markdown document
- Use headings and subheadings
- Use code blocks for formulas and code snippets
- Use tables where helpful
- Assume this will be read as course notes or a mini-textbook chapter
- Include file paths relative to repository root using exact filenames (e.g., `rectangle_1_02_conv_f0.csv`, not placeholder names)
- End with a **"Validation Checklist"** section: "Can you answer these 10 core questions? (Yes/No for each)" covering key concepts from all 6 parts

# CONSTRAINTS

- Do NOT generalize beyond this repo. Explicitly: Do NOT mention batch norm, dropout, residual connections, different architectures, pre-trained models, data augmentation, or training loops
- Do NOT introduce concepts not present in this specific codebase (8×8 images, 2 conv filters, 3×3 kernels, single dense layer)
- Do NOT skip steps or combine explanations into vague summaries
- Do NOT simplify at the cost of correctness. Precision over brevity

# SUCCESS CRITERION

A reader who understands tabular neural networks should be able to:
1. Explain every number produced by this code
2. Manually compute at least one convolution dot product and verify against a CSV file
3. Trace a single pixel difference from rectangle to triangle through all 8 layers
4. Describe exactly where CNNs diverge from tabular NNs (before flatten) and why they're identical after
5. Answer all 10 validation checklist questions with confidence

Final statement of understanding:
"I now understand CNNs, and I can explain every computation at every layer using data from this experiment."
