
"""
Stage 2: CNN Demo on Toy 8x8 Images (Rectangle vs Triangle)

This script:
1. Loads images generated by generate_toy_images.py
2. Converts them to tensors
3. Applies:
   - Convolution
   - ReLU
   - Max Pooling
   - Flatten
   - Dense layer
4. Writes every intermediate output to CSV for inspection

Goal: Conceptual clarity, not performance.
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import pandas as pd
import numpy as np
import os
from PIL import Image

# -----------------------------
# Configuration
# -----------------------------
BASE_DIR = "cnn_toy_data"
IMG_DIR = os.path.join(BASE_DIR, "images")
CSV_OUT = "cnn_demo_outputs"

# Clean up existing outputs
import shutil
if os.path.exists(CSV_OUT):
    shutil.rmtree(CSV_OUT)
os.makedirs(CSV_OUT, exist_ok=True)

# -----------------------------
# Load labels
# -----------------------------
labels_df = pd.read_csv(os.path.join(BASE_DIR, "labels.csv"))

# -----------------------------
# Simple CNN Model
# -----------------------------
class ToyCNN(nn.Module):
    def __init__(self):
        super().__init__()
        # One convolution layer: 1 input channel (grayscale), 2 filters
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=2, kernel_size=3)
        self.pool = nn.MaxPool2d(2, 2)
        # After conv (8x8 -> 6x6) and pooling (6x6 -> 3x3)
        self.fc = nn.Linear(2 * 3 * 3, 2)  # 2 classes

    def forward(self, x):
        x = self.conv1(x)
        x = F.relu(x)
        x = self.pool(x)
        x = x.view(x.size(0), -1)  # flatten
        x = self.fc(x)
        return x

model = ToyCNN()

# Loss (classification)
criterion = nn.CrossEntropyLoss()

# -----------------------------
# Process each image individually
# -----------------------------
for idx, row in labels_df.iterrows():
    img_name = row["image"]
    label = torch.tensor([row["label"]])

    # ----- Load image -----
    img_path = os.path.join(IMG_DIR, f"{img_name}.png")
    img = Image.open(img_path).convert("L")
    img_arr = np.array(img)

    # Save raw pixel matrix
    pd.DataFrame(img_arr).to_csv(f"{CSV_OUT}/{img_name}_01_input_pixels.csv", index=False)

    # ----- Convert to tensor -----
    x = torch.tensor(img_arr, dtype=torch.float32).unsqueeze(0).unsqueeze(0)
    # shape: (1, 1, 8, 8)

    # ----- Convolution -----
    conv_out = model.conv1(x)
    for f in range(conv_out.shape[1]):
        pd.DataFrame(conv_out[0, f].detach().numpy()).to_csv(
            f"{CSV_OUT}/{img_name}_02_conv_filter{f}.csv", index=False
        )

    # ----- ReLU -----
    relu_out = F.relu(conv_out)
    for f in range(relu_out.shape[1]):
        pd.DataFrame(relu_out[0, f].detach().numpy()).to_csv(
            f"{CSV_OUT}/{img_name}_03_relu_filter{f}.csv", index=False
        )

    # ----- Pooling -----
    pool_out = model.pool(relu_out)
    for f in range(pool_out.shape[1]):
        pd.DataFrame(pool_out[0, f].detach().numpy()).to_csv(
            f"{CSV_OUT}/{img_name}_04_pool_filter{f}.csv", index=False
        )

    # ----- Flatten -----
    flat = pool_out.view(1, -1)
    pd.DataFrame(flat.detach().numpy()).to_csv(
        f"{CSV_OUT}/{img_name}_05_flatten.csv", index=False
    )

    # ----- Dense layer -----
    logits = model.fc(flat)
    pd.DataFrame(logits.detach().numpy()).to_csv(
        f"{CSV_OUT}/{img_name}_06_logits.csv", index=False
    )

    # ----- Softmax -----
    probs = F.softmax(logits, dim=1)
    pd.DataFrame(probs.detach().numpy()).to_csv(
        f"{CSV_OUT}/{img_name}_07_softmax.csv", index=False
    )

    # ----- Loss -----
    loss = criterion(logits, label)
    with open(f"{CSV_OUT}/{img_name}_08_loss.txt", "w") as f:
        f.write(f"Loss: {loss.item()}")

print("CNN demo completed. Outputs written to:", CSV_OUT)
